{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa08f8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 20:17:39.320978: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-08 20:17:39.321003: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thuy/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log, dot, e, ndim\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#normalizing dataframe\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from wrapper import t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c25c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parkinsons: https://www.kaggle.com/paolocons/parkinson-desease-basic-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eaab233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>phon_R01_S50_2</td>\n",
       "      <td>174.188</td>\n",
       "      <td>230.978</td>\n",
       "      <td>94.261</td>\n",
       "      <td>0.00459</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.04087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07008</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>19.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448439</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>-6.538586</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>2.657476</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>phon_R01_S50_3</td>\n",
       "      <td>209.516</td>\n",
       "      <td>253.017</td>\n",
       "      <td>89.488</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.02751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.01810</td>\n",
       "      <td>19.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431674</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>-6.195325</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>2.784312</td>\n",
       "      <td>0.168895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>phon_R01_S50_4</td>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>phon_R01_S50_5</td>\n",
       "      <td>198.764</td>\n",
       "      <td>396.961</td>\n",
       "      <td>74.904</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.02296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>19.020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>-6.744577</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>2.138608</td>\n",
       "      <td>0.123306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>phon_R01_S50_6</td>\n",
       "      <td>214.289</td>\n",
       "      <td>260.277</td>\n",
       "      <td>77.973</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.01884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>21.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>-5.724056</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>2.555477</td>\n",
       "      <td>0.148569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "..              ...          ...           ...           ...             ...   \n",
       "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
       "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
       "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
       "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
       "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "..                ...       ...       ...         ...           ...  ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
       "\n",
       "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "..           ...      ...     ...     ...       ...       ...       ...   \n",
       "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
       "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
       "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
       "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
       "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
       "\n",
       "      spread2        D2       PPE  \n",
       "0    0.266482  2.301442  0.284654  \n",
       "1    0.335590  2.486855  0.368674  \n",
       "2    0.311173  2.342259  0.332634  \n",
       "3    0.334147  2.405554  0.368975  \n",
       "4    0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...  \n",
       "190  0.121952  2.657476  0.133050  \n",
       "191  0.129303  2.784312  0.168895  \n",
       "192  0.158453  2.679772  0.131728  \n",
       "193  0.207454  2.138608  0.123306  \n",
       "194  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data= pd.read_csv('./parkinsons.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2a1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"status\"]\n",
    "X = data.drop([\"name\",\"status\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e4161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0eb7e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f246fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_train = F.one_hot(y_train).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_test = F.one_hot(y_test).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3dfe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3489, 0.1283, 0.4423, 0.0924, 0.0909, 0.0877, 0.0879, 0.0877, 0.2954,\n",
       "        0.2449, 0.3713, 0.2647, 0.1786, 0.3714, 0.0589, 0.4202, 0.4617, 0.6383,\n",
       "        0.3639, 0.1836, 0.4097, 0.2940])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9926ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape None == allow dynamic number of rows; X_train.shape[1] == number of features\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='inputs')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1198ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34233/1039383836.py:3: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h1 = tf.layers.dense(X, 20, name='dense1')\n",
      "/home/thuy/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/tmp/ipykernel_34233/1039383836.py:7: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h2 = tf.layers.dense(h1, 10, name='dense2')\n",
      "/tmp/ipykernel_34233/1039383836.py:10: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  model1 = tf.layers.dense(h2, 2, name='dense3')\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "# X == features coming in, 30 == number of features == neurons\n",
    "h1 = tf.layers.dense(X, 20, name='dense1')\n",
    "h1 = h1 * h1\n",
    "# Second hidden layer\n",
    "# h1 == features coming in, 26 == number of neurons == arbitrary\n",
    "h2 = tf.layers.dense(h1, 10, name='dense2')\n",
    "h2 = h2 * h2\n",
    "# Last/output layar always has 1 neuron for binary classification problems\n",
    "model1 = tf.layers.dense(h2, 2, name='dense3')\n",
    "\n",
    "model = tf.sigmoid(model1, name='sigmoid')\n",
    "# model = approx_sigmoid(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0765f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.log_loss(y, model)\n",
    "\n",
    "# Define training operation\n",
    "training_op = tf.train.AdamOptimizer(.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be54ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 20:11:09.706779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-08 20:11:09.706805: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-08 20:11:09.706822: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (thuy-ThinkPad-T480): /proc/driver/nvidia/version does not exist\n",
      "2022-03-08 20:11:09.706990: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  | training loss: 0.680278  | test loss: 0.68641764\n",
      "epoch: 100  | training loss: 0.08343455  | test loss: 0.3056145\n",
      "epoch: 200  | training loss: 0.001975019  | test loss: 0.48794875\n",
      "epoch: 300  | training loss: 0.0005002758  | test loss: 0.58730185\n",
      "epoch: 400  | training loss: 0.0002284705  | test loss: 0.63609976\n",
      "epoch: 500  | training loss: 0.0001308683  | test loss: 0.66095704\n",
      "epoch: 600  | training loss: 8.469362e-05  | test loss: 0.67861295\n",
      "epoch: 700  | training loss: 5.916976e-05  | test loss: 0.6921353\n",
      "epoch: 800  | training loss: 4.3567954e-05  | test loss: 0.7032293\n",
      "epoch: 900  | training loss: 3.3333337e-05  | test loss: 0.7127024\n",
      "Accuracy: 0.9183673\n",
      "Accuracy without sigmoid:  0.9183673\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    # Train model with 1000 epochs\n",
    "    # saver.restore(sess, '/content/drive/MyDrive/Colab Notebooks/result/nn_data/net-1000')\n",
    "    for epoch in range(1000):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        if (epoch % 100 == 0):\n",
    "            training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "            test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "            print('epoch:',epoch,' | training loss:', training_loss, ' | test loss:', test_loss)\n",
    "    saved_path = saver.save(sess, './nn_data/net', global_step=1000)\n",
    "\n",
    "    # # Use model to classify test data\n",
    "    # classifications_on_test_data = sess.run(model, feed_dict={X: X_test})\n",
    "    \n",
    "    # # Check model accuracy\n",
    "    # classes = (classifications_on_test_data > .5).astype(int)\n",
    "    \n",
    "    # print('\\nAccuracy Score:',metrics.accuracy_score(y_test, classes))\n",
    "    \n",
    "    predictions = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: X_test, y: y_test}))\n",
    "    no_sig_predictions = tf.equal(tf.argmax(model1, 1), tf.argmax(y, 1))\n",
    "    no_sig_accuracy = tf.reduce_mean(tf.cast(no_sig_predictions, \"float\"))\n",
    "    print('Accuracy without sigmoid: ', no_sig_accuracy.eval({X: X_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf4f71",
   "metadata": {},
   "source": [
    "# PRE ENCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba31714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./nn_data/net-1000\n"
     ]
    }
   ],
   "source": [
    "# Restore session\n",
    "with tf.Session() as sess:\n",
    "\tsaver.restore(sess, './nn_data/net-1000')\n",
    "\twith tf.variable_scope('dense1', reuse=True):\n",
    "\t\tdense1_kernel_ = sess.run(tf.get_variable('kernel'))\n",
    "\t\tdense1_bias_ = sess.run(tf.get_variable('bias'))\n",
    "\twith tf.variable_scope('dense2', reuse=True):\n",
    "\t\tdense2_kernel_ = sess.run(tf.get_variable('kernel'))\n",
    "\t\tdense2_bias_ = sess.run(tf.get_variable('bias'))\n",
    "\twith tf.variable_scope('dense3', reuse=True):\n",
    "\t\tdense3_kernel_ = sess.run(tf.get_variable('kernel'))\n",
    "\t\tdense3_bias_ = sess.run(tf.get_variable('bias'))\n",
    "\tencoded_input_ = X.eval({X: X_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac498126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 20)\n",
      "(20,)\n",
      "(20, 10)\n",
      "(10,)\n",
      "(10, 2)\n",
      "(2,)\n",
      "(49, 22)\n"
     ]
    }
   ],
   "source": [
    "print(dense1_kernel_.shape)\n",
    "print(dense1_bias_.shape)\n",
    "print(dense2_kernel_.shape)\n",
    "print(dense2_bias_.shape)\n",
    "print(dense3_kernel_.shape)\n",
    "print(dense3_bias_.shape)\n",
    "print(encoded_input_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c630e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the outputs\n",
    "input_size = encoded_input_.shape[0]\n",
    "encoded_input = np.empty(shape=(input_size,encoded_input_.shape[1],5), dtype=np.uint64)\n",
    "dense1_kernel = np.empty(shape=(22,20,5), dtype=np.uint64)\n",
    "dense1_bias = np.empty(shape=(20,5), dtype=np.uint64)\n",
    "dense2_kernel = np.empty(shape=(20,10,5), dtype=np.uint64)\n",
    "dense2_bias = np.empty(shape=(10,5), dtype=np.uint64)\n",
    "dense3_kernel = np.empty(shape=(10,2,5), dtype=np.uint64)\n",
    "dense3_bias = np.empty(shape=(2,5), dtype=np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9bc10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights processing...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# WEIGHTS\n",
    "print(\"Weights processing...\")\n",
    "precision = 10\n",
    "for i in range(22):\n",
    "\tfor j in range(20):\n",
    "\t\tvalue = round(dense1_kernel_[i, j].item()*precision)\n",
    "\t\tfor t in range(5):\n",
    "\t\t\tdense1_kernel[i, j, t] = value % t_list[t]\n",
    "\n",
    "for i in range(20):\n",
    "\tfor j in range(10):\n",
    "\t\tvalue = round(dense2_kernel_[i, j].item()*precision)\n",
    "\t\tfor t in range(5):\n",
    "\t\t\tdense2_kernel[i, j, t] = value % t_list[t]\n",
    "\n",
    "for i in range(10):\n",
    "\tfor j in range(2):\n",
    "\t\tvalue = round(dense3_kernel_[i, j].item()*precision)\n",
    "\t\tfor t in range(5):\n",
    "\t\t\tdense3_kernel[i, j, t] = value % t_list[t]\n",
    "\n",
    "for i in range(20):\n",
    "\tvalue = round(dense1_bias_[i].item()*(precision**2))\n",
    "\tfor t in range(5):\n",
    "\t\tdense1_bias[i, t] = value % t_list[t]\n",
    "\n",
    "for i in range(10):\n",
    "\tvalue = round(dense2_bias_[i].item()*(precision**5))\n",
    "\tfor t in range(5):\n",
    "\t\tdense2_bias[i, t] = value % t_list[t]\n",
    "\n",
    "for i in range(2):\n",
    "\tvalue = round(dense3_bias_[i].item()*(precision**11))\n",
    "\tfor t in range(5):\n",
    "\t\tdense3_bias[i, t] = value % t_list[t]\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03cfff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input processing...\n"
     ]
    }
   ],
   "source": [
    "# INPUT\n",
    "print(\"Input processing...\")\n",
    "for i in range(input_size):\n",
    "\tfor j in range(encoded_input_.shape[1]):\n",
    "\t\t\tvalue = round(encoded_input_[i,j].item()*precision)\n",
    "\t\t\tfor t in range(5):\n",
    "\t\t\t\tencoded_input[i,j,t] = value % t_list[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc343226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors stored\n"
     ]
    }
   ],
   "source": [
    "# Store the encoded tensors\n",
    "np.save(\"./output_data/plain_layer_0\", encoded_input)\n",
    "np.save(\"./nn_data/dense1_kernel\", dense1_kernel)\n",
    "np.save(\"./nn_data/dense1_bias\", dense1_bias)\n",
    "np.save(\"./nn_data/dense2_kernel\", dense2_kernel)\n",
    "np.save(\"./nn_data/dense2_bias\", dense2_bias)\n",
    "np.save(\"./nn_data/dense3_kernel\", dense3_kernel)\n",
    "np.save(\"./nn_data/dense3_bias\", dense3_bias)\n",
    "\n",
    "print(\"Tensors stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491bbe7",
   "metadata": {},
   "source": [
    "# INFERE PLAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539fae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from wrapper import t_list\n",
    "\n",
    "t_size = len(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cffbdfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHTS\n",
    "dense1_kernel = np.load(\"./nn_data/dense1_kernel.npy\")\n",
    "dense1_bias = np.load(\"./nn_data/dense1_bias.npy\")\n",
    "dense2_kernel = np.load(\"./nn_data/dense2_kernel.npy\")\n",
    "dense2_bias = np.load(\"./nn_data/dense2_bias.npy\")\n",
    "dense3_kernel = np.load(\"./nn_data/dense3_kernel.npy\")\n",
    "dense3_bias = np.load(\"./nn_data/dense3_bias.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99afea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_input = np.load(\"./output_data/plain_layer_0.npy\")\n",
    "examples_count = plain_input.shape[0]\n",
    "plain_output = np.empty((examples_count,22,5), dtype=np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5c2f647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_input[...,0].dot(dense1_kernel[...,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c873f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 1/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 1: dense1\n",
    "print(\"Computing layer 1/5...\")\n",
    "temp = np.empty((examples_count,20,t_size), dtype=np.uint64)\n",
    "for t_index in range(t_size):\n",
    "\ttemp[...,t_index] = (plain_input[...,t_index].dot(dense1_kernel[...,t_index])) % t_list[t_index]\n",
    "\ttemp[...,t_index] = (temp[...,t_index] + dense1_bias[...,t_index]) % t_list[t_index]\n",
    "plain_output = temp\n",
    "temp = None\n",
    "np.save(\"./output_data/plain_layer_1\", plain_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd18899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 2/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 2: square activation function\n",
    "print(\"Computing layer 2/5...\")\n",
    "plain_output = plain_output*plain_output\n",
    "for t_index in range(t_size):\n",
    "\tplain_output[...,t_index] = plain_output[...,t_index] % t_list[t_index]\n",
    "np.save(\"./output_data/plain_layer_2\", plain_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9dc1450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 3/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 3: dense2\n",
    "print(\"Computing layer 3/5...\")\n",
    "temp = np.empty((examples_count,10,t_size), dtype=np.uint64)\n",
    "for t_index in range(t_size):\n",
    "\ttemp[...,t_index] = (plain_output[...,t_index].dot(dense2_kernel[...,t_index])) % t_list[t_index]\n",
    "\ttemp[...,t_index] = (temp[...,t_index] + dense2_bias[...,t_index]) % t_list[t_index]\n",
    "plain_output = temp\n",
    "temp = None\n",
    "np.save(\"./output_data/plain_layer_3\", plain_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baac8bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 4/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 4: square activation function\n",
    "print(\"Computing layer 4/5...\")\n",
    "plain_output = plain_output*plain_output\n",
    "for t_index in range(t_size):\n",
    "\tplain_output[...,t_index] = plain_output[...,t_index] % t_list[t_index]\n",
    "np.save(\"./output_data/plain_layer_4\", plain_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89778bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 5/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 5: dense3\n",
    "print(\"Computing layer 5/5...\")\n",
    "temp = np.empty((examples_count,2,t_size), dtype=np.uint64)\n",
    "for t_index in range(t_size):\n",
    "\ttemp[...,t_index] = (plain_output[...,t_index].dot(dense3_kernel[...,t_index])) % t_list[t_index]\n",
    "\ttemp[...,t_index] = (temp[...,t_index] + dense3_bias[...,t_index]) % t_list[t_index]\n",
    "plain_output = temp\n",
    "temp = None\n",
    "np.save(\"./output_data/plain_layer_5\", plain_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2837a",
   "metadata": {},
   "source": [
    "# INFERE ENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e844afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from wrapper import SEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "679d4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEALobj = SEAL()\n",
    "q_list = SEALobj.q_list\n",
    "k_list = SEALobj.k_list\n",
    "n_parm = SEALobj.n_parm\n",
    "enc_poly_size = SEALobj.enc_poly_size\n",
    "q_size = len(q_list)\n",
    "t_size = len(SEALobj.t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a87a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_object_dtype(tensoreuint):\n",
    "\tshape = tensoreuint.shape\n",
    "\ttensoreuint.shape = (tensoreuint.size,)\n",
    "\tnew = np.empty((tensoreuint.size,), dtype=object)\n",
    "\tfor i in range(tensoreuint.size):\n",
    "\t\tnew[i] = int(tensoreuint[i].item())\n",
    "\tnew.shape = shape\n",
    "\treturn new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c0ed749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHTS\n",
    "dense1_kernel = np.load(\"./nn_data/dense1_kernel.npy\")\n",
    "dense1_bias = np.load(\"./nn_data/dense1_bias.npy\")\n",
    "dense2_kernel = np.load(\"./nn_data/dense2_kernel.npy\")\n",
    "dense2_bias = np.load(\"./nn_data/dense2_bias.npy\")\n",
    "dense3_kernel = np.load(\"./nn_data/dense3_kernel.npy\")\n",
    "dense3_bias = np.load(\"./nn_data/dense3_bias.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c46df15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypting the input...\n"
     ]
    }
   ],
   "source": [
    "# INPUT AND OUTPUT DATA\n",
    "print(\"Encrypting the input...\")\n",
    "encrypted_input = np.load(\"./output_data/plain_layer_0.npy\") # not yet encrypted\n",
    "examples_count = encrypted_input.shape[0]\n",
    "encrypted_input = SEALobj.encrypt_tensor(encrypted_input) # now it is\n",
    "np.save(\"./output_data/enc_layer_0\", encrypted_input)\n",
    "poly_groups_count = encrypted_input.shape[0]//enc_poly_size\n",
    "encrypted_output = np.empty((encrypted_input.shape[0],22,t_size), dtype=np.uint64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ad4b390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 1/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 1: fully connected layer\n",
    "print(\"Computing layer 1/5...\")\n",
    "encrypted_output = to_object_dtype(encrypted_input)\n",
    "dense1_kernel = to_object_dtype(dense1_kernel)\n",
    "## kernel\n",
    "temp = np.empty((encrypted_output.shape[0],20,t_size), dtype=object)\n",
    "for t_index in range(t_size):\n",
    "\ttemp[...,t_index] = encrypted_output[...,t_index].dot(dense1_kernel[...,t_index])\n",
    "encrypted_output = temp\n",
    "temp = None\n",
    "## % q\n",
    "for axis1 in range(encrypted_output.shape[1]):\n",
    "\tfor axis2 in range(encrypted_output.shape[2]):\n",
    "\t\tfor poly_group_index in range(poly_groups_count):\n",
    "\t\t\tfor size_index in range(2):\n",
    "\t\t\t\tfor q_index in range(q_size):\n",
    "\t\t\t\t\tfor n_index in range(n_parm+1):\n",
    "\t\t\t\t\t\taxis0 = poly_group_index*enc_poly_size + size_index*q_size*(n_parm+1) + q_index*(n_parm+1) + n_index\n",
    "\t\t\t\t\t\ttemp = encrypted_output[axis0,axis1,axis2]\n",
    "\t\t\t\t\t\ttemp = temp % q_list[q_index]\n",
    "\t\t\t\t\t\tencrypted_output[axis0,axis1,axis2] = temp\n",
    "## bias\n",
    "for axis1 in range(encrypted_output.shape[1]):\n",
    "\tfor axis2 in range(encrypted_output.shape[2]):\n",
    "\t\tfor poly_group_index in range(poly_groups_count):\n",
    "\t\t\tfor q_index in range(q_size):\n",
    "\t\t\t\taxis0 = poly_group_index*enc_poly_size + ((n_parm+1)*q_index)\n",
    "\t\t\t\ttemp = encrypted_output[axis0,axis1,axis2]\n",
    "\t\t\t\ttemp = temp + dense1_bias[axis1,axis2].item()*k_list[axis2][q_index]\n",
    "\t\t\t\ttemp = temp % q_list[q_index]\n",
    "\t\t\t\tencrypted_output[axis0,axis1,axis2] = temp\n",
    "np.save(\"./output_data/enc_layer_1\", encrypted_output) # !!!! encrypted_output has dtype=object. To load it use the function at the end of the file !!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f14b7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 2/5...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LAYER 2: square activation function\n",
    "print(\"Computing layer 2/5...\")\n",
    "encrypted_output = SEALobj.square_tensor(encrypted_output)\n",
    "np.save(\"./output_data/enc_layer_2\", encrypted_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c71b6ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 3/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 3: fully connected layer\n",
    "print(\"Computing layer 3/5...\")\n",
    "encrypted_output = to_object_dtype(encrypted_output)\n",
    "dense2_kernel = to_object_dtype(dense2_kernel)\n",
    "## kernel\n",
    "temp = np.empty((encrypted_output.shape[0],10,t_size), dtype=object)\n",
    "for t_index in range(t_size):\n",
    "\ttemp[...,t_index] = encrypted_output[...,t_index].dot(dense2_kernel[...,t_index])\n",
    "encrypted_output = temp\n",
    "temp = None\n",
    "## % q\n",
    "for axis1 in range(encrypted_output.shape[1]):\n",
    "\tfor axis2 in range(encrypted_output.shape[2]):\n",
    "\t\tfor poly_group_index in range(poly_groups_count):\n",
    "\t\t\tfor size_index in range(2):\n",
    "\t\t\t\tfor q_index in range(q_size):\n",
    "\t\t\t\t\tfor n_index in range(n_parm+1):\n",
    "\t\t\t\t\t\taxis0 = poly_group_index*enc_poly_size + size_index*q_size*(n_parm+1) + q_index*(n_parm+1) + n_index\n",
    "\t\t\t\t\t\ttemp = encrypted_output[axis0,axis1,axis2]\n",
    "\t\t\t\t\t\ttemp = temp % q_list[q_index]\n",
    "\t\t\t\t\t\tencrypted_output[axis0,axis1,axis2] = temp\n",
    "## bias\n",
    "for axis1 in range(encrypted_output.shape[1]):\n",
    "\tfor axis2 in range(encrypted_output.shape[2]):\n",
    "\t\tfor poly_group_index in range(poly_groups_count):\n",
    "\t\t\tfor q_index in range(q_size):\n",
    "\t\t\t\taxis0 = poly_group_index*enc_poly_size + ((n_parm+1)*q_index)\n",
    "\t\t\t\ttemp = encrypted_output[axis0,axis1,axis2]\n",
    "\t\t\t\ttemp = temp + dense2_bias[axis1,axis2].item()*k_list[axis2][q_index]\n",
    "\t\t\t\ttemp = temp % q_list[q_index]\n",
    "\t\t\t\tencrypted_output[axis0,axis1,axis2] = temp\n",
    "np.save(\"./output_data/enc_layer_3\", encrypted_output) # !!!! encrypted_output has dtype=object. To load it use the function at the end of the file !!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "734f7305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 4/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 4: square activation function\n",
    "print(\"Computing layer 4/5...\")\n",
    "encrypted_output = SEALobj.square_tensor(encrypted_output)\n",
    "np.save(\"./output_data/enc_layer_4\", encrypted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aa52558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing layer 5/5...\n"
     ]
    }
   ],
   "source": [
    "# LAYER 5: fully connected layer\n",
    "print(\"Computing layer 5/5...\")\n",
    "encrypted_output = to_object_dtype(encrypted_output)\n",
    "dense3_kernel = to_object_dtype(dense3_kernel)\n",
    "## kernel\n",
    "temp = np.empty((encrypted_output.shape[0],2,t_size), dtype=object)\n",
    "for t_index in range(t_size):\n",
    "\ttemp[...,t_index] = encrypted_output[...,t_index].dot(dense3_kernel[...,t_index])\n",
    "encrypted_output = temp\n",
    "temp = None\n",
    "## % q\n",
    "for axis1 in range(encrypted_output.shape[1]):\n",
    "\tfor axis2 in range(encrypted_output.shape[2]):\n",
    "\t\tfor poly_group_index in range(poly_groups_count):\n",
    "\t\t\tfor size_index in range(2):\n",
    "\t\t\t\tfor q_index in range(q_size):\n",
    "\t\t\t\t\tfor n_index in range(n_parm+1):\n",
    "\t\t\t\t\t\taxis0 = poly_group_index*enc_poly_size + size_index*q_size*(n_parm+1) + q_index*(n_parm+1) + n_index\n",
    "\t\t\t\t\t\ttemp = encrypted_output[axis0,axis1,axis2]\n",
    "\t\t\t\t\t\ttemp = temp % q_list[q_index]\n",
    "\t\t\t\t\t\tencrypted_output[axis0,axis1,axis2] = temp\n",
    "## bias\n",
    "for axis1 in range(encrypted_output.shape[1]):\n",
    "\tfor axis2 in range(encrypted_output.shape[2]):\n",
    "\t\tfor poly_group_index in range(poly_groups_count):\n",
    "\t\t\tfor q_index in range(q_size):\n",
    "\t\t\t\taxis0 = poly_group_index*enc_poly_size + ((n_parm+1)*q_index)\n",
    "\t\t\t\ttemp = encrypted_output[axis0,axis1,axis2]\n",
    "\t\t\t\ttemp = temp + dense3_bias[axis1,axis2].item()*k_list[axis2][q_index]\n",
    "\t\t\t\ttemp = temp % q_list[q_index]\n",
    "\t\t\t\tencrypted_output[axis0,axis1,axis2] = temp\n",
    "np.save(\"./output_data/enc_layer_5\", encrypted_output) # !!!! encrypted_output has dtype=object. To load it use the function at the end of the file !!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76728733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrypting the output...\n"
     ]
    }
   ],
   "source": [
    "# DECRYPT\n",
    "print(\"Decrypting the output...\")\n",
    "decrypted_output = SEALobj.decrypt_tensor(encrypted_output, examples_count)\n",
    "encrypted_output = None\n",
    "np.save(\"./output_data/decrypted_layer_5\", decrypted_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935d0df",
   "metadata": {},
   "source": [
    "# POST_DECODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b454e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86f4bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_output_exists = os.path.isfile(\"./output_data/plain_layer_5.npy\")\n",
    "decrypted_output_exists = os.path.isfile(\"./output_data/decrypted_layer_5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80480cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_Euclidean_algorithm(a, b):\n",
    "\tb0 = b\n",
    "\tx0, x1 = 0, 1\n",
    "\tif b == 1: return 1\n",
    "\twhile a > 1:\n",
    "\t\tq = a // b\n",
    "\t\ta, b = b, a%b\n",
    "\t\tx0, x1 = x1 - q * x0, x0\n",
    "\tif x1 < 0: x1 += b0\n",
    "\treturn x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eb04ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_remainder_theorem(array):\n",
    "\tresult = 0\n",
    "\tfor t_index in range(len(array)):\n",
    "\t\tresult += array[t_index].item() * bezout_coefficients[t_index] * t_product_over_t[t_index]\n",
    "\treturn result % t_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edbeff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crt_inverse(tensor):\n",
    "\texamples_count = tensor.shape[0]\n",
    "\ttemp = np.empty(tensor.shape[:-1], dtype=object)\n",
    "\tfor i in range(examples_count):\n",
    "\t\tfor j in range(2):\n",
    "\t\t\ttemp[i, j] = chinese_remainder_theorem(plain_output[i, j, :])\n",
    "\t\t\tif (temp[i, j]>negative_threshold):\n",
    "\t\t\t\ttemp[i, j] = temp[i, j] - t_product\n",
    "\treturn temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5754301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRT PARAMETERS\n",
    "# compute the producte of all t, and the threshold for negative numbers:\n",
    "#   t_product\n",
    "#   negative_threshold\n",
    "t_product = 1\n",
    "for t_index in range(len(t_list)):\n",
    "\tt_product = t_product * t_list[t_index]\n",
    "negative_threshold = t_product // 2\n",
    "# compute t_product // t and the Bezout coefficients, for all t: \n",
    "#   t_product_over_t\n",
    "#   bezout_coefficients\n",
    "t_product_over_t = []\n",
    "bezout_coefficients = []\n",
    "for t_index in range(len(t_list)):\n",
    "\tt_product_over_t.append(t_product // t_list[t_index])\n",
    "\ttemp = extended_Euclidean_algorithm(t_product_over_t[t_index], t_list[t_index])\n",
    "\tbezout_coefficients.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2718cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Plain and decrypted outputs coincide ----\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE PREDICTIONS\n",
    "string = \"\"\n",
    "if (plain_output_exists):\n",
    "\tplain_output = np.load(\"./output_data/plain_layer_5.npy\")\n",
    "if (decrypted_output_exists):\n",
    "\tdecrypted_output = np.load(\"./output_data/decrypted_layer_5.npy\")\n",
    "\tif (plain_output_exists):\n",
    "\t\tif (np.array_equal(plain_output, decrypted_output)):\n",
    "\t\t\tprint(\"---- Plain and decrypted outputs coincide ----\")\n",
    "\t\t\tcn_predictions = crt_inverse(decrypted_output)\n",
    "\t\t\tstring = \"Accuracy with SEAL encryption:\"\n",
    "\t\telse:\n",
    "\t\t\tprint(\"---- Plain and decrypted outputs are different. Computing accuracy with plain output ----\")\n",
    "\t\t\tcn_predictions = crt_inverse(plain_output)\n",
    "\t\t\tstring = \"Accuracy with integer numbers (no encryption):\"\n",
    "\telse:\n",
    "\t\tprint(\"---- plain_layer_5.npy file is missing. Can't compare decrypted and plain outputs ----\")\n",
    "\t\tcn_predictions = crt_inverse(decrypted_output)\n",
    "\t\tstring = \"Accuracy with SEAL encryption:\"\n",
    "else:\n",
    "\tprint(\"---- decrypted_layer_5.npy file is missing. Can't compare decrypted and plain outputs ----\")\n",
    "\tprint(\"Computing accuracy with plain output...\")\n",
    "\tcn_predictions = crt_inverse(plain_output)\n",
    "\tstring = \"Accuracy with integer numbers (no encryption):\"\n",
    "cn_predictions = np.argmax(cn_predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfe77259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./nn_data/net-1000\n",
      "Accuracy with tensorflow and no CRT: 0.9183673\n",
      "Accuracy with SEAL encryption: 0.9183673\n",
      "Number of swapped predictions:  2\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# PRINT ACCURACIES\n",
    "with tf.Session() as sess:\n",
    "\tsaver.restore(sess, './nn_data/net-1000')\n",
    "\n",
    "\ttf_guessed_predictions = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "\ttf_accuracy = tf.reduce_mean(tf.cast(tf_guessed_predictions, \"float\"))\n",
    "\tcn_guessed_predictions = tf.equal(cn_predictions, tf.argmax(y, 1))\n",
    "\tcn_accuracy = tf.reduce_mean(tf.cast(cn_guessed_predictions, \"float\"))\n",
    "\n",
    "\n",
    "\ttf_guessed_predictions_ = tf_guessed_predictions.eval({X: X_test, y: y_test})\n",
    "\tcn_guessed_predictions_ = cn_guessed_predictions.eval({y: y_test})\n",
    "\tswapped_predictions_count = 0\n",
    "\tfor i in range(tf_guessed_predictions_.size):\n",
    "\t\tif (tf_guessed_predictions_[i]!=cn_guessed_predictions_[i]):\n",
    "\t\t\tswapped_predictions_count = swapped_predictions_count + 1\n",
    "\n",
    "\n",
    "\tprint(\"Accuracy with tensorflow and no CRT:\", tf_accuracy.eval({X: X_test, y: y_test}))\n",
    "\tprint(string, cn_accuracy.eval({X: X_test, y: y_test}))\n",
    "\tprint(\"Number of swapped predictions: \", swapped_predictions_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24891392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
